{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to find topics within a corpus of emails with the **LDA** algorithm (Unsupervised Learning in NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úâÔ∏è Here is a collection of 1K+ ***unlabelled emails***. Let's try to ***extract topics*** from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/lda_data'\n",
    "\n",
    "data = pd.read_csv(url, sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning**) ‚ùì You're used to it by now... Clean up! Store the cleaned text in a new column \"clean_text\" of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>gldcunixbcccolumbiaedu gary l dare subject sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>atterlepvelaacsoaklandedu cardinal ximenez sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>minerkuhubccukansedu subject ancient book orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>atterlepvelaacsoaklandedu cardinal ximenez sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>vzhivovsuperiorcarletonca vladimir zhivov subj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  gldcunixbcccolumbiaedu gary l dare subject sta...  \n",
       "1  atterlepvelaacsoaklandedu cardinal ximenez sub...  \n",
       "2  minerkuhubccukansedu subject ancient book orga...  \n",
       "3  atterlepvelaacsoaklandedu cardinal ximenez sub...  \n",
       "4  vzhivovsuperiorcarletonca vladimir zhivov subj...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocessing(sentence):\n",
    "       # YOUR CODE HERE\n",
    "    \n",
    "    # remove whitespace \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # lowercase characters\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # remove numbers \n",
    "    sentence = \"\".join([char for char in sentence if not char.isdigit()])\n",
    "    \n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation: \n",
    "        sentence = sentence.replace(punctuation, \"\")\n",
    "        \n",
    "    # tokenize\n",
    "    tokens = word_tokenize(sentence)\n",
    "    \n",
    "     # remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens_without_stopwords = [token for token in tokens if not token in stop_words]\n",
    "    \n",
    "    # lemmatize\n",
    "    lemmatized_verbs = [WordNetLemmatizer().lemmatize(token, pos=\"v\") for token in tokens_without_stopwords]\n",
    "    lemmatized_nouns = [WordNetLemmatizer().lemmatize(token, pos=\"n\") for token in lemmatized_verbs]\n",
    "    \n",
    "    return \" \".join(lemmatized_nouns)\n",
    "\n",
    "# Clean reviews\n",
    "data[\"clean_text\"] = data[\"text\"].apply(preprocessing)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Train a LDA model to extract potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg</th>\n",
       "      <th>aacc</th>\n",
       "      <th>aadams</th>\n",
       "      <th>aafreenetcarletonca</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronbinahccbrandeisedu</th>\n",
       "      <th>aaroncathenamitedu</th>\n",
       "      <th>aassists</th>\n",
       "      <th>...</th>\n",
       "      <th>zombo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorasterism</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 17317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  \\\n",
       "0     0.0   \n",
       "1     0.0   \n",
       "2     0.0   \n",
       "3     0.0   \n",
       "4     0.0   \n",
       "...   ...   \n",
       "1194  0.0   \n",
       "1195  0.0   \n",
       "1196  0.0   \n",
       "1197  0.0   \n",
       "1198  0.0   \n",
       "\n",
       "      aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
       "0                                                   0.0                                 \n",
       "1                                                   0.0                                 \n",
       "2                                                   0.0                                 \n",
       "3                                                   0.0                                 \n",
       "4                                                   0.0                                 \n",
       "...                                                 ...                                 \n",
       "1194                                                0.0                                 \n",
       "1195                                                0.0                                 \n",
       "1196                                                0.0                                 \n",
       "1197                                                0.0                                 \n",
       "1198                                                0.0                                 \n",
       "\n",
       "      aacc  aadams  aafreenetcarletonca  aargh  aaron  \\\n",
       "0      0.0     0.0             0.000000    0.0    0.0   \n",
       "1      0.0     0.0             0.088609    0.0    0.0   \n",
       "2      0.0     0.0             0.000000    0.0    0.0   \n",
       "3      0.0     0.0             0.000000    0.0    0.0   \n",
       "4      0.0     0.0             0.000000    0.0    0.0   \n",
       "...    ...     ...                  ...    ...    ...   \n",
       "1194   0.0     0.0             0.000000    0.0    0.0   \n",
       "1195   0.0     0.0             0.000000    0.0    0.0   \n",
       "1196   0.0     0.0             0.000000    0.0    0.0   \n",
       "1197   0.0     0.0             0.000000    0.0    0.0   \n",
       "1198   0.0     0.0             0.000000    0.0    0.0   \n",
       "\n",
       "      aaronbinahccbrandeisedu  aaroncathenamitedu  aassists  ...  zombo  \\\n",
       "0                         0.0                 0.0       0.0  ...    0.0   \n",
       "1                         0.0                 0.0       0.0  ...    0.0   \n",
       "2                         0.0                 0.0       0.0  ...    0.0   \n",
       "3                         0.0                 0.0       0.0  ...    0.0   \n",
       "4                         0.0                 0.0       0.0  ...    0.0   \n",
       "...                       ...                 ...       ...  ...    ...   \n",
       "1194                      0.0                 0.0       0.0  ...    0.0   \n",
       "1195                      0.0                 0.0       0.0  ...    0.0   \n",
       "1196                      0.0                 0.0       0.0  ...    0.0   \n",
       "1197                      0.0                 0.0       0.0  ...    0.0   \n",
       "1198                      0.0                 0.0       0.0  ...    0.0   \n",
       "\n",
       "         zone  zoo  zoom  zorasterism  zubov  zupancic  zurich  zwart  zzzzzz  \n",
       "0     0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "1     0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "2     0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "3     0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "4     0.07373  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "...       ...  ...   ...          ...    ...       ...     ...    ...     ...  \n",
       "1194  0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "1195  0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "1196  0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "1197  0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "1198  0.00000  0.0   0.0          0.0    0.0       0.0     0.0    0.0     0.0  \n",
       "\n",
       "[1199 rows x 17317 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorized_data = pd.DataFrame(vectorizer.fit_transform(data.clean_text).toarray())\n",
    "vectorized_data.columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.315571</td>\n",
       "      <td>0.486086</td>\n",
       "      <td>0.137467</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.723813</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.206870</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.886472</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.011165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.163271</td>\n",
       "      <td>0.578338</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>0.188940</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.009922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.664616</td>\n",
       "      <td>0.227041</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.517082</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.370163</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.797783</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.010465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.089294</td>\n",
       "      <td>0.763392</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.018414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.225380</td>\n",
       "      <td>0.681873</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1   Topic 2   Topic 3   Topic 4   Topic 5   Topic 6   Topic 7  \\\n",
       "0     0.008696  0.315571  0.486086  0.137467  0.008696  0.008700  0.008696   \n",
       "1     0.009275  0.009275  0.916525  0.009275  0.009275  0.009275  0.009275   \n",
       "2     0.008664  0.008666  0.723813  0.008664  0.206870  0.008664  0.008664   \n",
       "3     0.011165  0.011165  0.886472  0.011165  0.011165  0.011165  0.011165   \n",
       "4     0.009921  0.163271  0.578338  0.009921  0.009922  0.009921  0.009922   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1194  0.013542  0.013543  0.664616  0.227041  0.013542  0.013542  0.013542   \n",
       "1195  0.014095  0.014095  0.517082  0.014094  0.014095  0.370163  0.014094   \n",
       "1196  0.010465  0.010467  0.797783  0.010465  0.010465  0.010465  0.118489   \n",
       "1197  0.018414  0.089294  0.763392  0.018414  0.018414  0.018414  0.018414   \n",
       "1198  0.011593  0.225380  0.681873  0.011593  0.011593  0.011593  0.011593   \n",
       "\n",
       "       Topic 8   Topic 9  Topic 10  \n",
       "0     0.008696  0.008696  0.008696  \n",
       "1     0.009275  0.009275  0.009275  \n",
       "2     0.008664  0.008664  0.008664  \n",
       "3     0.011165  0.024206  0.011165  \n",
       "4     0.188940  0.009921  0.009922  \n",
       "...        ...       ...       ...  \n",
       "1194  0.013550  0.013542  0.013542  \n",
       "1195  0.014094  0.014094  0.014094  \n",
       "1196  0.010465  0.010472  0.010465  \n",
       "1197  0.018414  0.018414  0.018414  \n",
       "1198  0.011593  0.011593  0.011593  \n",
       "\n",
       "[1199 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_components = 10\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=100)\n",
    "\n",
    "topics = lda.fit_transform(vectorized_data)\n",
    "topics = pd.DataFrame(topics, columns=[f\"Topic {i+1}\" for i in range(n_components)])\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded for you a  function that prints the words associated with the potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Print the topics extracted by your LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('grass', 4.064857256520005), ('valley', 3.8134220050726233), ('chuck', 3.131125223274644), ('petchgvggvgtekcom', 3.050467805117499), ('cell', 2.344385802640014), ('petch', 2.1515652355304873), ('daily', 2.138701707725435), ('statemaine', 1.0349620650615423), ('finalswho', 1.0349620650615423), ('ata', 1.0224572473286888)]\n",
      "Topic 1:\n",
      "[('espn', 8.766644264207741), ('ranger', 8.354649262523514), ('captain', 7.710132818628686), ('islander', 6.5050200907771245), ('gary', 6.023975669218992), ('mask', 5.793995695648306), ('pt', 5.752492841557317), ('hawk', 5.664793328320538), ('jet', 5.650328188638847), ('dare', 5.633748474990385)]\n",
      "Topic 2:\n",
      "[('god', 35.723133778996655), ('game', 26.688698002351035), ('go', 26.185827082569567), ('would', 25.94013754551293), ('team', 25.359105336545575), ('one', 24.121526980633046), ('write', 23.414177149625477), ('say', 23.368415293740068), ('line', 22.88364693411444), ('subject', 22.71792375093564)]\n",
      "Topic 3:\n",
      "[('cdkaupaneosncsuedu', 1.0443215540667932), ('kaupang', 1.0443215540667932), ('adirondack', 1.0342335226325283), ('utica', 1.0107907871595043), ('providence', 0.9486734799043289), ('bowman', 0.9212912720154437), ('baltimore', 0.8639604441722816), ('binghamton', 0.8158991276490323), ('reincarnation', 0.7868426707963752), ('springfield', 0.7659858501204092)]\n",
      "Topic 4:\n",
      "[('chi', 3.884664365175438), ('det', 3.527075785362851), ('bos', 3.299224077574318), ('tor', 3.2698828828855158), ('cal', 2.9851591131941237), ('pit', 2.8487265784915063), ('que', 2.0244001164634566), ('van', 1.9892007819095237), ('buf', 1.9798722951235181), ('stl', 1.8115844646604724)]\n",
      "Topic 5:\n",
      "[('tie', 3.155084612883303), ('breaker', 2.5350784100859145), ('moncton', 1.7010592672202383), ('howl', 1.4144786575988966), ('gargle', 1.1754799538769742), ('breakerisles', 1.047511942282623), ('manretard', 1.047511942282623), ('ahve', 1.047511942282623), ('anderson', 1.0274704755733837), ('ecac', 0.9910796352902038)]\n",
      "Topic 6:\n",
      "[('genocide', 1.378636003763847), ('pregnancy', 1.2684156294621136), ('germanborn', 1.07627176199249), ('serbian', 1.0279873783850604), ('kellett', 0.9874796647005617), ('jkellettnetcomcom', 0.9874796647005617), ('fmsalvateosncsuedu', 0.88919443892281), ('salvatore', 0.88919443892281), ('revdaknetcomcom', 0.8851402217336038), ('dab', 0.8063445369527067)]\n",
      "Topic 7:\n",
      "[('hispanic', 1.6363657958328992), ('lee', 1.3602606177721739), ('stamber', 1.1327454997071194), ('pera', 1.1074981734151934), ('czech', 1.0948110468148438), ('teamwork', 1.0733582189012492), ('holger', 1.0427266871012484), ('icopcsabuedu', 1.0124365495907186), ('sarossstarbasespdlouisvilleedu', 0.8615660673743222), ('caldcsissuneevirginiaedu', 0.8383685900742908)]\n",
      "Topic 8:\n",
      "[('hrivnak', 2.271171741809293), ('gtdaprismgatechedu', 2.1776266755582143), ('hornet', 1.5343854224571376), ('patton', 1.5343854224571376), ('friedman', 1.4991597831937267), ('hudson', 1.2313981121893383), ('sda', 1.2271119008797122), ('poll', 1.1642363720089575), ('todd', 1.1125536328262104), ('jonomacakrtsgmotcom', 1.0615296715401017)]\n",
      "Topic 9:\n",
      "[('jcjtellabscom', 1.6126811726549952), ('jeff', 1.2484169801964957), ('ideological', 1.178457230684936), ('denounce', 1.0924106563632843), ('jcj', 0.975199128446434), ('translator', 0.9529579087624146), ('emotion', 0.869307209594861), ('oser', 0.8511343526233915), ('interference', 0.8460178577531645), ('native', 0.844382078394122)]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print_topics(lda, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Predict the document-topic mixture of a new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Prediction)** ‚ùì\n",
    "\n",
    "Now that your LDA model is fitted, you can use it to predict the topics of a new text.\n",
    "\n",
    "1. Vectorize the example\n",
    "2. Use the LDA on the vectorized example to predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "example_vectorized = vectorizer.transform(example).toarray()\n",
    "example_vectorized = pd.DataFrame(example_vectorized, columns= vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1        2         3         4         5         6  \\\n",
      "0  0.027739  0.214135  0.56395  0.027739  0.027739  0.027739  0.027739   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.027739  0.027739  0.027739  \n",
      "topic 0 : 0.027739368234211182\n",
      "topic 1 : 0.21413514299992303\n"
     ]
    }
   ],
   "source": [
    "lda_vectors = lda.transform(example_vectorized)\n",
    "print(pd.DataFrame(lda_vectors))\n",
    "print(\"topic 0 :\", lda_vectors[0][0])\n",
    "print(\"topic 1 :\", lda_vectors[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to implement an LDA quickly.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
